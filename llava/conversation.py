"""Defines structures and templates for handling conversations in LLaVA-style models."""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/12_conversation.ipynb.

# %% auto 0
__all__ = ['project_root', 'project_root_str', 'conv_llava_plain', 'conv_vicuna_v1', 'conv_templates', 'default_conversation',
           'SeparatorStyle', 'Conversation', 'get_conv_template']

# %% ../nbs/12_conversation.ipynb 3
import sys
from pathlib import Path
import os

# Assumes the notebook is run from the project root or one level down (e.g., nbs/)
# Navigate up to the project root (where settings.ini or .git likely exists)
project_root = Path(os.getcwd())
# Simple check: If settings.ini is not in cwd, assume we are in nbs/ and go up one level
if not (project_root / 'settings.ini').exists() and (project_root.parent / 'settings.ini').exists():
    project_root = project_root.parent

project_root_str = str(project_root.resolve())

if project_root_str not in sys.path:
    print(f"Adding project root to sys.path: {project_root_str}")
    sys.path.insert(0, project_root_str)
else:
    print(f"Project root already in sys.path: {project_root_str}")

# %% ../nbs/12_conversation.ipynb 4
import dataclasses
from enum import auto, Enum
from typing import List, Tuple, Dict, Any, Union

# %% ../nbs/12_conversation.ipynb 6
class SeparatorStyle(Enum):
    """Different separator styles for conversations."""
    # Generic styles
    SINGLE = auto()
    TWO = auto()
    MPT = auto()
    PLAIN = auto() # Special case for simple image-caption pairs
    LLAMA_2 = auto()
    # Specific model styles (add as needed)
    VICUNA = auto() # Equivalent to TWO for older versions
    CHATML = auto()
    CHATGLM = auto()
    DOLLY = auto()
    RWKV = auto()
    PHOENIX = auto()
    ROBIN = auto()
    FALCON_CHAT = auto()

# %% ../nbs/12_conversation.ipynb 8
@dataclasses.dataclass
class Conversation:
    """A class that manages prompt generation and conversation history for different models."""
    # The system prompt message
    system: str
    # Roles for user and assistant
    roles: List[str]
    # The conversation history messages. List of lists, where each inner list contains [role, message]. Role is string, message is string or None.
    messages: List[List[str]]
    # Message offset
    offset: int
    # Separator style
    sep_style: SeparatorStyle
    # Separator token(s)
    sep: str
    # Optional second separator token
    sep2: str = None
    # Stop criteria (list of stop strings or token IDs)
    stop_str: Union[str, List[str]] = None
    # Stop token IDs (list of token IDs)
    stop_token_ids: List[int] = None

    def get_prompt(self) -> str:
        """Generates the prompt string based on the conversation history and style."""

        # --- Handling for TWO/VICUNA Separator Style ---
        if self.sep_style == SeparatorStyle.TWO or self.sep_style == SeparatorStyle.VICUNA:
            seps = [self.sep, self.sep2] # Expects [space, EOS]
            if seps[1] is None:
                raise ValueError("SeparatorStyle.TWO/VICUNA requires both sep (sep1) and sep2 to be defined.")

            # Start with system prompt + first separator (space)
            ret = self.system + seps[0] if self.system else ""
            # Append messages
            for i, (role, message) in enumerate(self.messages):
                if message:
                    # Append "ROLE: Message"
                    ret += role + ": " + message
                    # Append the separator based on turn index (sep1 after USER, sep2 after ASSISTANT)
                    ret += seps[i % 2]
                else: # Handle prompt marker (message is None)
                    ret += role + ":" # Append "ASSISTANT:", no separators needed after marker
            return ret # Return directly

        # --- Handling for other Separator Styles ---
        ret = ""
        if self.system:
            ret += self.system
            if self.sep_style != SeparatorStyle.CHATML: # CHATML handles sep differently
                 ret += self.sep

        # Format messages for non-TWO/VICUNA styles
        for i, (role, message) in enumerate(self.messages):
            if message: # Handle actual messages
                if self.sep_style == SeparatorStyle.PLAIN:
                     ret += role + message + self.sep
                elif self.sep_style == SeparatorStyle.CHATML:
                     ret += role + "\n" + message + self.sep + ("\n" if i < len(self.messages)-1 else "")
                # Add other specific style logic here if needed
                else: # Default/Fallback
                    ret += role + message + self.sep
            else: # Handle prompt markers (message is None)
                if self.sep_style == SeparatorStyle.PLAIN:
                     ret += role + self.sep
                elif self.sep_style == SeparatorStyle.CHATML:
                     ret += role + "\n"
                # Add other specific style logic here if needed
                else:
                     ret += role

        # --- Final Cleanup for PLAIN ---
        if self.sep_style == SeparatorStyle.PLAIN:
             if self.sep:
                 ret = ret.rstrip() # Remove any trailing whitespace first
                 if not ret.endswith(self.sep):
                     ret += self.sep

        return ret

    def append_message(self, role: str, message: str | None):
        """Appends a new message to the conversation history."""
        self.messages.append([role, message])

    def copy(self):
        """Creates a deep copy of the conversation object."""
        import copy
        return copy.deepcopy(self)

    def dict(self):
        """Converts the conversation object to a dictionary."""
        return {
            "system": self.system,
            "roles": self.roles,
            "messages": self.messages,
            "offset": self.offset,
            "sep_style": self.sep_style.name,
            "sep": self.sep,
            "sep2": self.sep2,
            "stop_str": self.stop_str,
            "stop_token_ids": self.stop_token_ids,
        }

# %% ../nbs/12_conversation.ipynb 12
# Template for Stage 1 Pretraining ('plain' style)
conv_llava_plain = Conversation(
    system="", # No system prompt
    roles=("", ""), # Roles are often ignored, but placeholders needed
    messages=[], # History is built dynamically
    offset=0,
    sep_style=SeparatorStyle.PLAIN,
    sep="\n", # Separator is a newline
    stop_str=None,
    stop_token_ids=None
)

# Template for Vicuna v1 (Instruction Tuning - Stage 2)
conv_vicuna_v1 = Conversation(
    system="A chat between a curious user and an artificial intelligence assistant. "
           "The assistant gives helpful, detailed, and polite answers to the user's questions.",
    roles=("USER", "ASSISTANT"),
    messages=[],
    offset=0,
    sep_style=SeparatorStyle.TWO, # Uses two separators
    sep=" ", # Space separator between turns
    sep2="</s>", # EOS token as the second separator (end of conversation)
    stop_str="</s>",
    # stop_token_ids=[2], # Example, assuming tokenizer.eos_token_id is 2
    # Note: stop_token_ids should be set based on the actual tokenizer used later
    stop_token_ids=None
)

# Add other templates as needed (e.g., 'v0', 'llama_2', 'chatml') based on LLaVA reference
# ...

# --- Template Dictionary --- 
conv_templates = {
    "plain": conv_llava_plain,
    "v1": conv_vicuna_v1,
    # Add other templates here
    # "v0": conv_vicuna_v0, 
    # "vicuna_v1": conv_vicuna_v1, # Alias
}

# --- Default Conversation --- 
# Set a default conversation template (can be overridden)
default_conversation = conv_vicuna_v1 

# --- Functions to get conversation templates ---
def get_conv_template(name: str) -> Conversation:
    """Gets a conversation template by name.
    
    Args:
        name: The name of the conversation template.
        
    Returns:
        A deep copy of the requested conversation template.
        
    Raises:
        ValueError: If the template name is not found.
    """
    if name not in conv_templates:
        raise ValueError(f"Unknown conversation template: {name}. Available templates: {list(conv_templates.keys())}")
    return conv_templates[name].copy()
