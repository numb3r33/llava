{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive Model Components\n",
    "\n",
    "> Defines adaptive components for the LLaVA model, starting with the Adaptive Patcher interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp model.adaptive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding project root to sys.path: /workspace/llava\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Assumes the notebook is run from the project root or one level down (e.g., nbs/)\n",
    "# Navigate up to the project root (where settings.ini or .git likely exists)\n",
    "project_root = Path(os.getcwd())\n",
    "# Simple check: If settings.ini is not in cwd, assume we are in nbs/ and go up one level\n",
    "if not (project_root / 'settings.ini').exists() and (project_root.parent / 'settings.ini').exists():\n",
    "    project_root = project_root.parent\n",
    "\n",
    "project_root_str = str(project_root.resolve())\n",
    "\n",
    "if project_root_str not in sys.path:\n",
    "    print(f\"Adding project root to sys.path: {project_root_str}\")\n",
    "    sys.path.insert(0, project_root_str)\n",
    "else:\n",
    "    # print(f\"Project root already in sys.path: {project_root_str}\") # Less verbose\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Dict, Any, Optional, Tuple\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6.1: Define Adaptive Patcher Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This base class defines the interface for any adaptive patching strategy. Subclasses will implement specific logic (e.g., variable resolution, attention-based patching)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AdaptivePatcher(nn.Module):\n",
    "    \"\"\"Base interface for adaptive image patching modules.\n",
    "\n",
    "    Subclasses should implement the `forward` method to dynamically process\n",
    "    an input image (or its features) based on content or context (like text instructions)\n",
    "    and return a structured representation of image features for the projector.\n",
    "    \"\"\"\n",
    "    def __init__(self, config: Dict[str, Any]):\n",
    "        \"\"\"Initializes the Adaptive Patcher.\n",
    "\n",
    "        Args:\n",
    "            config: Dictionary containing configuration relevant to the patcher strategy.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        # Potentially load sub-modules or parameters based on config['strategy']\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        pixel_values: torch.Tensor, \n",
    "        text_features: Optional[torch.Tensor] = None, \n",
    "        raw_image: Optional[Image.Image] = None,\n",
    "        **kwargs\n",
    "    ) -> Tuple[torch.Tensor, Optional[Dict[str, Any]]]:\n",
    "        \"\"\"Processes the input image adaptively.\n",
    "\n",
    "        Args:\n",
    "            pixel_values: Preprocessed image tensor (e.g., B x C x H x W).\n",
    "                           Could represent the full image or specific patches.\n",
    "            text_features: Optional tensor containing embeddings of the instruction text (e.g., B x S_txt x D_txt).\n",
    "                           Needed for text-guided patching strategies.\n",
    "            raw_image: Optional PIL image, potentially needed for calculating aspect ratio \n",
    "                       or other properties not easily derived from pixel_values alone.\n",
    "            **kwargs: Additional keyword arguments specific to the patching strategy.\n",
    "\n",
    "        Returns:\n",
    "            A tuple containing:\n",
    "            - torch.Tensor: The processed image features ready for projection \n",
    "                            (e.g., selected patches, global+local combination).\n",
    "                            Shape might be (B, NumFeatures, D_vision) or similar.\n",
    "            - Optional[Dict[str, Any]]: Optional dictionary containing metadata about the patching \n",
    "                                      (e.g., strategy used, number of patches).\n",
    "                                      This can be useful for debugging or conditional logic later.\n",
    "        \n",
    "        Raises:\n",
    "            NotImplementedError: This base method must be implemented by subclasses.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Subclasses must implement the forward method.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### AdaptivePatcher\n",
       "\n",
       ">      AdaptivePatcher (config:Dict[str,Any])\n",
       "\n",
       "*Base interface for adaptive image patching modules.\n",
       "\n",
       "    Subclasses should implement the `forward` method to dynamically process\n",
       "    an input image (or its features) based on content or context (like text instructions)\n",
       "    and return a structured representation of image features for the projector.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### AdaptivePatcher\n",
       "\n",
       ">      AdaptivePatcher (config:Dict[str,Any])\n",
       "\n",
       "*Base interface for adaptive image patching modules.\n",
       "\n",
       "    Subclasses should implement the `forward` method to dynamically process\n",
       "    an input image (or its features) based on content or context (like text instructions)\n",
       "    and return a structured representation of image features for the projector.*"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(AdaptivePatcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "metadata": {
   "path": "nbs/21_model_adaptive.ipynb",
   "skip_save": true
  },
  "nbdev": {
   "doc_path": "_docs",
   "lib_path": "llava"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}